(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{108:function(e,t,n){"use strict";n.d(t,"a",(function(){return b})),n.d(t,"b",(function(){return d}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=a.a.createContext({}),u=function(e){var t=a.a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},b=function(e){var t=u(e.components);return a.a.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},s=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,p=c(e,["components","mdxType","originalType","parentName"]),b=u(n),s=r,d=b["".concat(i,".").concat(s)]||b[s]||m[s]||o;return n?a.a.createElement(d,l(l({ref:t},p),{},{components:n})):a.a.createElement(d,l({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=s;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return a.a.createElement.apply(null,i)}return a.a.createElement.apply(null,n)}s.displayName="MDXCreateElement"},98:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return i})),n.d(t,"toc",(function(){return l})),n.d(t,"default",(function(){return p}));var r=n(3),a=(n(0),n(108));const o={},i={type:"mdx",permalink:"/opensource",source:"@site/src\\pages\\opensource.md"},l=[{value:"Under development",id:"under-development",children:[{value:"\ud83e\uddec Reinforcement Learning experiments",id:"\ud83e\uddec-reinforcement-learning-experiments",children:[]},{value:"\u265f Beth",id:"\u265f-beth",children:[]},{value:"\ud83e\udd16 Westworld",id:"-westworld",children:[]},{value:"\ud83e\udda0 Abio",id:"\ud83e\udda0-abio",children:[]}]}],c={toc:l};function p({components:e,...t}){return Object(a.b)("wrapper",Object(r.a)({},c,t,{components:e,mdxType:"MDXLayout"}),Object(a.b)("h1",{id:"open-source-portfolio"},"Open Source portfolio"),Object(a.b)("p",null,Object(a.b)("em",{parentName:"p"},"Discover my latest open source contributions ",Object(a.b)("a",{parentName:"em",href:"https://github.com/TheoLvs"},"https://github.com/TheoLvs"))),Object(a.b)("h2",{id:"under-development"},"Under development"),Object(a.b)("h3",{id:"\ud83e\uddec-reinforcement-learning-experiments"},"\ud83e\uddec ",Object(a.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/reinforcement-learning"},"Reinforcement Learning experiments")),Object(a.b)("p",null,"Personal experiments on Reinforcement Learning made since 2014"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Environment creation"),Object(a.b)("li",{parentName:"ul"},"Classical RL techniques applied to standard environments (Atari, Tic Tac Toe)"),Object(a.b)("li",{parentName:"ul"},"RL applied to predictive maintenance and Datacenter management (Q Learning, Deep Q Learning, Policy Gradients)"),Object(a.b)("li",{parentName:"ul"},"RL applied to logistics optimization (TSP, VRP)"),Object(a.b)("li",{parentName:"ul"},"RL applied to Chrome Dino game (Evolutionary Search, Frugal RL)")),Object(a.b)("h3",{id:"\u265f-beth"},"\u265f ",Object(a.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/beth"},"Beth")),Object(a.b)("p",null,"Python library to experiment with the game of chess"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Play chess games in Python in Jupyter notebooks and the command line"),Object(a.b)("li",{parentName:"ul"},"Different AI engines implemented (Random, Minimax, LSTM)"),Object(a.b)("li",{parentName:"ul"},"Framework to develop open source engines or learning features easily  ")),Object(a.b)("h3",{id:"-westworld"},"\ud83e\udd16 ",Object(a.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/westworld"},"Westworld")),Object(a.b)("p",null,"Python library to develop multi-agents simulations"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Complex simulations and render in a few lines of code"),Object(a.b)("li",{parentName:"ul"},"Collider and obstacles avoidance"),Object(a.b)("li",{parentName:"ul"},"Shortest-path algorithms")),Object(a.b)("h3",{id:"\ud83e\udda0-abio"},"\ud83e\udda0 ",Object(a.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/cellular-automata"},"Abio")),Object(a.b)("p",null,"Python library to develop cellular automata"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Accelerated 1D and 2D cellular automata using PyTorch"),Object(a.b)("li",{parentName:"ul"},"Visualization in the notebook and with video/gifs")))}p.isMDXComponent=!0}}]);