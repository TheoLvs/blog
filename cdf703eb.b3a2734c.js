(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{92:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return r})),n.d(t,"toc",(function(){return l})),n.d(t,"default",(function(){return b}));var a=n(3),i=(n(0),n(104));const o={},r={type:"mdx",permalink:"/opensource",source:"@site/src\\pages\\opensource.md"},l=[{value:"Under development",id:"under-development",children:[{value:"\ud83e\uddec Reinforcement Learning experiments",id:"\ud83e\uddec-reinforcement-learning-experiments",children:[]},{value:"\u265f Beth",id:"\u265f-beth",children:[]},{value:"\ud83e\udd16 Westworld",id:"-westworld",children:[]},{value:"\ud83e\udda0 Abio",id:"\ud83e\udda0-abio",children:[]}]}],c={toc:l};function b({components:e,...t}){return Object(i.b)("wrapper",Object(a.a)({},c,t,{components:e,mdxType:"MDXLayout"}),Object(i.b)("h1",{id:"open-source-portfolio"},"Open Source portfolio"),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"Discover my latest open source contributions ",Object(i.b)("a",{parentName:"em",href:"https://github.com/TheoLvs"},"https://github.com/TheoLvs"))),Object(i.b)("h2",{id:"under-development"},"Under development"),Object(i.b)("h3",{id:"\ud83e\uddec-reinforcement-learning-experiments"},"\ud83e\uddec ",Object(i.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/reinforcement-learning"},"Reinforcement Learning experiments")),Object(i.b)("p",null,"Personal experiments on Reinforcement Learning made since 2014"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Environment creation"),Object(i.b)("li",{parentName:"ul"},"Classical RL techniques applied to standard environments (Atari, Tic Tac Toe)"),Object(i.b)("li",{parentName:"ul"},"RL applied to predictive maintenance and Datacenter management (Q Learning, Deep Q Learning, Policy Gradients)"),Object(i.b)("li",{parentName:"ul"},"RL applied to logistics optimization (TSP, VRP)"),Object(i.b)("li",{parentName:"ul"},"RL applied to Chrome Dino game (Evolutionary Search, Frugal RL)")),Object(i.b)("h3",{id:"\u265f-beth"},"\u265f ",Object(i.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/beth"},"Beth")),Object(i.b)("p",null,"Python library to experiment with the game of chess"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Play chess games in Python in Jupyter notebooks and the command line"),Object(i.b)("li",{parentName:"ul"},"Different AI engines implemented (Random, Minimax, LSTM)"),Object(i.b)("li",{parentName:"ul"},"Framework to develop open source engines or learning features easily  ")),Object(i.b)("h3",{id:"-westworld"},"\ud83e\udd16 ",Object(i.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/westworld"},"Westworld")),Object(i.b)("p",null,"Python library to develop multi-agents simulations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Complex simulations and render in a few lines of code"),Object(i.b)("li",{parentName:"ul"},"Collider and obstacles avoidance"),Object(i.b)("li",{parentName:"ul"},"Shortest-path algorithms")),Object(i.b)("h3",{id:"\ud83e\udda0-abio"},"\ud83e\udda0 ",Object(i.b)("a",{parentName:"h3",href:"https://github.com/TheoLvs/cellular-automata"},"Abio")),Object(i.b)("p",null,"Python library to develop cellular automata"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Accelerated 1D and 2D cellular automata using PyTorch"),Object(i.b)("li",{parentName:"ul"},"Visualization in the notebook and with video/gifs")))}b.isMDXComponent=!0}}]);